{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_qwukc5b"
   },
   "source": [
    "# Exercise: Heterogenous Plugin and the DevCloud\n",
    "\n",
    "In this exercise, we will load a model using the hetero plugin on to the FPGA and CPU, and the GPU and CPU. We will then perform an inference on it and compare the time it takes to do the same for each device pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_z8bfs11"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_z8bfs11-id_d97ox8f\"><i></i><button>Graffiti Sample Button (edit me)</button></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_0untint"
   },
   "source": [
    "\n",
    "\n",
    "#### Set up paths so we can run Dev Cloud utilities\n",
    "You *must* run this every time they enter a Workspace session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_axn1sb2"
   },
   "outputs": [],
   "source": [
    "%env PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel_devcloud_support'))\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_mhiayyz"
   },
   "source": [
    "## The model\n",
    "\n",
    "We will be using the `vehicle-license-plate-detection-barrier-0106` model for this exercise. Remember that to run a model using the HETERO Plugin, we need to use FP16 as the model precision.\n",
    "\n",
    "The model is present in the `/data/models/intel` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_ltf95ei"
   },
   "source": [
    "# Step 1: Creating a Python Script\n",
    "\n",
    "The first step is to create a python script that you can use to load the model and perform an inference. I have used the `writefile` magic to create a python file called `inference_on_device.py`. You will need to complete this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_bpywo8s"
   },
   "outputs": [],
   "source": [
    "%%writefile inference_on_device.py\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from openvino.inference_engine import IENetwork\n",
    "from openvino.inference_engine import IECore\n",
    "import argparse\n",
    "\n",
    "def main(args):\n",
    "    model=args.model_path\n",
    "    model_weights=model+'.bin'\n",
    "    model_structure=model+'.xml'\n",
    "    \n",
    "    start=time.time()\n",
    "    \n",
    "    # TODO: Load the model on VPU\n",
    "    \n",
    "    print(f\"Time taken to load model = {time.time()-start} seconds\")\n",
    "    \n",
    "    # Reading and Preprocessing Image\n",
    "    input_img=cv2.imread('car.png')\n",
    "    input_img=cv2.resize(input_img, (300,300), interpolation = cv2.INTER_AREA)\n",
    "    input_img=np.moveaxis(input_img, -1, 0)\n",
    "\n",
    "    # TODO: Prepare the model for inference (create input dict etc.)\n",
    "    \n",
    "    start=time.time()\n",
    "    for _ in range(100):\n",
    "        # TODO: Run Inference in a Loop\n",
    "    \n",
    "    print(f\"Time Taken to run 100 Inference is = {time.time()-start} seconds\")\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_path', required=True)\n",
    "    parser.add_argument('--device', default=None)\n",
    "    \n",
    "    args=parser.parse_args() \n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_1rnmf5g"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_1rnmf5g-id_nmeqj1a\"><i></i><button>Hide Solution</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_nmeqj1a"
   },
   "outputs": [],
   "source": [
    "%%writefile inference_on_device.py\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IENetwork\n",
    "from openvino.inference_engine import IECore\n",
    "import argparse\n",
    "\n",
    "def main(args):\n",
    "    model=args.model_path\n",
    "    model_weights=model+'.bin'\n",
    "    model_structure=model+'.xml'\n",
    "    \n",
    "    start=time.time()\n",
    "    model=IENetwork(model_structure, model_weights)\n",
    "\n",
    "    core = IECore()\n",
    "    net = core.load_network(network=model, device_name=args.device, num_requests=1)\n",
    "    load_time=time.time()-start\n",
    "    print(f\"Time taken to load model = {load_time} seconds\")\n",
    "    \n",
    "    # Get the name of the input node\n",
    "    input_name=next(iter(model.inputs))\n",
    "\n",
    "    # Reading and Preprocessing Image\n",
    "    input_img=cv2.imread('/data/resources/car.png')\n",
    "    input_img=cv2.resize(input_img, (300,300), interpolation = cv2.INTER_AREA)\n",
    "    input_img=np.moveaxis(input_img, -1, 0)\n",
    "\n",
    "    # Running Inference in a loop on the same image\n",
    "    input_dict={input_name:input_img}\n",
    "\n",
    "    start=time.time()\n",
    "    for _ in range(100):\n",
    "        net.infer(input_dict)\n",
    "    \n",
    "    inference_time=time.time()-start\n",
    "    fps=100/inference_time\n",
    "    \n",
    "    print(f\"Time Taken to run 100 Inference is = {inference_time} seconds\")\n",
    "    \n",
    "    with open(f\"/output/{args.path}.txt\", \"w\") as f:\n",
    "        f.write(str(load_time)+'\\n')\n",
    "        f.write(str(inference_time)+'\\n')\n",
    "        f.write(str(fps)+'\\n')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_path', required=True)\n",
    "    parser.add_argument('--device', default=None)\n",
    "    parser.add_argument('--path', default=None)\n",
    "    \n",
    "    args=parser.parse_args() \n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_ufbi2ll"
   },
   "source": [
    "## Step 2: Creating a job submission script\n",
    "\n",
    "To submit a job to the devcloud, we need to create a script. I have named the script as `inference_hetero_model_job.sh`.\n",
    "\n",
    "Can you write a script that will take the model path and device as a command line argument and then call the python file you created in the previous cell with the path to the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_5r13clu"
   },
   "outputs": [],
   "source": [
    "%%writefile inference_model_job.sh\n",
    "\n",
    "#TODO: Create job submission script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_f1nbmn9"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_f1nbmn9-id_ia7yjlq\"><i></i><button>Hide Solution</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "graffitiCellId": "id_ia7yjlq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference_model_job.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference_model_job.sh\n",
    "#!/bin/bash\n",
    "\n",
    "exec 1>/output/stdout.log 2>/output/stderr.log\n",
    "\n",
    "mkdir -p /output\n",
    "\n",
    "DEVICE=$1\n",
    "MODELPATH=$2\n",
    "\n",
    "\n",
    "source /opt/intel/init_openvino.sh\n",
    "aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/2019R4_PL1_FP16_MobileNet_Clamp.aocx\n",
    "\n",
    "\n",
    "# Run the load model python script\n",
    "python3 inference_on_device.py  --model_path ${MODELPATH} --device ${DEVICE}\n",
    "\n",
    "cd /output\n",
    "\n",
    "tar zcvf output.tgz *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_28fed2h"
   },
   "source": [
    "## Step 3a: Running on the FPGA and CPU\n",
    "\n",
    "In the cell below, can you write the qsub command that will submit your job to the CPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_6awpacu"
   },
   "outputs": [],
   "source": [
    "fpga_cpu_job = # TODO: Write qsub command\n",
    "print(fpga_cpu_job[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_cvp3lyi"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_cvp3lyi-id_chmeh50\"><i></i><button>Hide Solution</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "graffitiCellId": "id_chmeh50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S4JnyfRTRLgnuYAELRGDGPPyWcBeLu5K\n"
     ]
    }
   ],
   "source": [
    "fpga_cpu_job = !qsub inference_model_job.sh -d . -l nodes=1:tank-870:i5-6500te:iei-mustang-f100-a10 -F \"HETERO:FPGA,CPU /data/models/intel/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106 fpga_cpu_stats\" -N store_core \n",
    "print(fpga_cpu_job[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_io25c53"
   },
   "source": [
    "## Step 3b: Running on CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_v5klpi1"
   },
   "outputs": [],
   "source": [
    "fpga_gpu_job = # TODO: Write qsub command\n",
    "print(fpga_gpu_job[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_7k34s6u"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_7k34s6u-id_022l4bj\"><i></i><button>Hide Solution</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "graffitiCellId": "id_022l4bj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eh6UyjrAVHGzoOtXzCduZQ2Xew2GnSJf\n"
     ]
    }
   ],
   "source": [
    "cpu_gpu_job = !qsub inference_model_job.sh -d . -l nodes=tank-870:i5-6500te:intel-hd-530 -F \"HETERO:CPU,GPU /data/models/intel/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106 cpu_gpu_stats\" -N store_core \n",
    "print(cpu_gpu_job[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_io25c53"
   },
   "source": [
    "## Step 3c: Running on FPGA, GPU and CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_v5klpi1"
   },
   "outputs": [],
   "source": [
    "fpga_gpu_cpu_job = # TODO: Write qsub command\n",
    "print(fpga_gpu_cpu_job[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_mxh5ozv"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_mxh5ozv-id_qicoukm\"><i></i><button>Hide Solution</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "graffitiCellId": "id_qicoukm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0nJKbX8NJKvekIoxvVQ77gTk9bt2ldBk\n"
     ]
    }
   ],
   "source": [
    "fpga_gpu_cpu_job = !qsub inference_model_job.sh -d . -l nodes=tank-870:i5-6500te:intel-hd-530:iei-mustang-f100-a10 -F \"HETERO:FPGA,GPU,CPU /data/models/intel/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106 fpga_gpu_cpu_stats\" -N store_core \n",
    "print(fpga_gpu_cpu_job[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_8ym2smn"
   },
   "source": [
    "## Step 4: Getting the Live Stat Values\n",
    "\n",
    "By running the below command, we can see the live status of the commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_clj7fxa"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_clj7fxa-id_d3gqjz0\"><i></i><button>Graffiti Sample Button (edit me)</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_zig7qg5"
   },
   "outputs": [],
   "source": [
    "import liveQStat\n",
    "liveQStat.liveQStat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_2vp5y4m"
   },
   "source": [
    "## Step 5a: Get the results for FPGA and CPU\n",
    "\n",
    "Running the cell below will get the output files from our job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_cygruth"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_cygruth-id_6nd1x96\"><i></i><button>Graffiti Sample Button (edit me)</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "graffitiCellId": "id_zpdshwo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getResults() is blocking until results of the job (id:S4JnyfRTRLgnuYAELRGDGPPyWcBeLu5K) are ready.\n",
      "Please wait................................................Success!\n",
      "output.tgz was downloaded in the same folder as this notebook.\n"
     ]
    }
   ],
   "source": [
    "import get_results\n",
    "\n",
    "get_results.getResults(fpga_cpu_job[0], get_stderr=True, filename=\"output.tgz\", blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "graffitiCellId": "id_0quk13q"
   },
   "outputs": [],
   "source": [
    "!tar zxf output.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "graffitiCellId": "id_l1gs5j5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTELFPGAOCLSDKROOT is set to /opt/altera/aocl-pro-rte/aclrte-linux64. Using that.\r\n",
      "\r\n",
      "aoc was not found, but aocl was found. Assuming only RTE is installed.\r\n",
      "\r\n",
      "AOCL_BOARD_PACKAGE_ROOT is set to /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/BSP/a10_1150_sg1. Using that.\r\n",
      "Adding /opt/altera/aocl-pro-rte/aclrte-linux64/bin to PATH\r\n",
      "Adding /opt/altera/aocl-pro-rte/aclrte-linux64/host/linux64/lib to LD_LIBRARY_PATH\r\n",
      "Adding /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/BSP/a10_1150_sg1/linux64/lib to LD_LIBRARY_PATH\r\n",
      "[setupvars.sh] OpenVINO environment initialized\r\n",
      "aocl program: Running program from /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/BSP/a10_1150_sg1/linux64/libexec\r\n",
      "Programming device: a10gx_2ddr : Intel Vision Accelerator Design with Intel Arria 10 FPGA (acla10_1150_sg10)\r\n",
      "Program succeed. \r\n",
      "Time taken to load model = 4.475625038146973 seconds\r\n",
      "Time Taken to run 100 Inference is = 0.8625667095184326 seconds\r\n",
      "None.txt\r\n",
      "stderr.log\r\n"
     ]
    }
   ],
   "source": [
    "!cat stdout.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_gykmtow"
   },
   "source": [
    "## Step 5b: Get the result for CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "graffitiCellId": "id_8w79u8w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getResults() is blocking until results of the job (id:Eh6UyjrAVHGzoOtXzCduZQ2Xew2GnSJf) are ready.\n",
      "Please wait...Success!\n",
      "output.tgz was downloaded in the same folder as this notebook.\n"
     ]
    }
   ],
   "source": [
    "import get_results\n",
    "\n",
    "get_results.getResults(cpu_gpu_job[0], filename=\"output.tgz\", blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "graffitiCellId": "id_kv4qcd6"
   },
   "outputs": [],
   "source": [
    "!tar zxf output.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "graffitiCellId": "id_etgr4le"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTELFPGAOCLSDKROOT is set to /opt/altera/aocl-pro-rte/aclrte-linux64. Using that.\r\n",
      "\r\n",
      "aoc was not found, but aocl was found. Assuming only RTE is installed.\r\n",
      "\r\n",
      "AOCL_BOARD_PACKAGE_ROOT is set to /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/BSP/a10_1150_sg1. Using that.\r\n",
      "Adding /opt/altera/aocl-pro-rte/aclrte-linux64/bin to PATH\r\n",
      "Adding /opt/altera/aocl-pro-rte/aclrte-linux64/host/linux64/lib to LD_LIBRARY_PATH\r\n",
      "Adding /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/BSP/a10_1150_sg1/linux64/lib to LD_LIBRARY_PATH\r\n",
      "[setupvars.sh] OpenVINO environment initialized\r\n",
      "aocl program: Running program from /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/BSP/a10_1150_sg1/linux64/libexec\r\n",
      "Programming device: a10gx_2ddr : Intel Vision Accelerator Design with Intel Arria 10 FPGA (acla10_1150_sg10)\r\n",
      "Program succeed. \r\n",
      "DetectionOutput_Reshape_priors_/Output_0/Data__const is CPU\r\n",
      "DetectionOutput_Reshape_conf_ is CPU\r\n",
      "SSD/concat_reshape_softmax/mbox_conf_final is CPU\r\n",
      "SSD/concat_reshape_softmax/Reshape is GPU\r\n",
      "SSD/concat_reshape_softmax/mbox_conf_logits is GPU\r\n",
      "SSD/ssd_head_1/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_1/layer_18/output_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "DetectionOutput_Reshape_loc_ is CPU\r\n",
      "SSD/concat_reshape_softmax/mbox_loc_final is CPU\r\n",
      "SSD/ssd_head_1/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_1/layer_18/output_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_2/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_2/feature_map_1_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_2/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_2/feature_map_1_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_3/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_3/feature_map_2_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_3/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_3/feature_map_2_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_4/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_4/feature_map_3_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_4/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_4/feature_map_3_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_5/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_5/feature_map_4_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_5/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_5/feature_map_4_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head/layer_14/output_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head/layer_14/output_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "Time taken to load model = 11.25682806968689 seconds\r\n",
      "Time Taken to run 100 Inference is = 1.122713565826416 seconds\r\n",
      "None.txt\r\n",
      "stderr.log\r\n"
     ]
    }
   ],
   "source": [
    "!cat stdout.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_gykmtow"
   },
   "source": [
    "## Step 5c: Get the result for FPGA, GPU and CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "graffitiCellId": "id_8w79u8w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getResults() is blocking until results of the job (id:0nJKbX8NJKvekIoxvVQ77gTk9bt2ldBk) are ready.\n",
      "Please wait.....Success!\n",
      "output.tgz was downloaded in the same folder as this notebook.\n"
     ]
    }
   ],
   "source": [
    "import get_results\n",
    "\n",
    "get_results.getResults(fpga_gpu_cpu_job[0], filename=\"output.tgz\", blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "graffitiCellId": "id_kv4qcd6"
   },
   "outputs": [],
   "source": [
    "!tar zxf output.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "graffitiCellId": "id_etgr4le"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTELFPGAOCLSDKROOT is set to /opt/altera/aocl-pro-rte/aclrte-linux64. Using that.\r\n",
      "\r\n",
      "aoc was not found, but aocl was found. Assuming only RTE is installed.\r\n",
      "\r\n",
      "AOCL_BOARD_PACKAGE_ROOT is set to /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/BSP/a10_1150_sg1. Using that.\r\n",
      "Adding /opt/altera/aocl-pro-rte/aclrte-linux64/bin to PATH\r\n",
      "Adding /opt/altera/aocl-pro-rte/aclrte-linux64/host/linux64/lib to LD_LIBRARY_PATH\r\n",
      "Adding /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/BSP/a10_1150_sg1/linux64/lib to LD_LIBRARY_PATH\r\n",
      "[setupvars.sh] OpenVINO environment initialized\r\n",
      "aocl program: Running program from /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/BSP/a10_1150_sg1/linux64/libexec\r\n",
      "Programming device: a10gx_2ddr : Intel Vision Accelerator Design with Intel Arria 10 FPGA (acla10_1150_sg10)\r\n",
      "Program succeed. \r\n",
      "DetectionOutput_Reshape_priors_/Output_0/Data__const is CPU\r\n",
      "DetectionOutput_Reshape_conf_ is CPU\r\n",
      "SSD/concat_reshape_softmax/mbox_conf_final is CPU\r\n",
      "SSD/concat_reshape_softmax/Reshape is GPU\r\n",
      "SSD/concat_reshape_softmax/mbox_conf_logits is GPU\r\n",
      "SSD/ssd_head_1/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_1/layer_18/output_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "DetectionOutput_Reshape_loc_ is CPU\r\n",
      "SSD/concat_reshape_softmax/mbox_loc_final is CPU\r\n",
      "SSD/ssd_head_1/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_1/layer_18/output_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_2/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_2/feature_map_1_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_2/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_2/feature_map_1_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_3/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_3/feature_map_2_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_3/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_3/feature_map_2_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_4/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_4/feature_map_3_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_4/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_4/feature_map_3_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_5/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_5/feature_map_4_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head_5/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head_5/feature_map_4_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head/Flatten_1/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head/layer_14/output_mbox_conf/BiasAdd/Add/Transpose is GPU\r\n",
      "SSD/ssd_head/Flatten/flatten/Reshape is GPU\r\n",
      "SSD/ssd_head/layer_14/output_mbox_loc/BiasAdd/Add/Transpose is GPU\r\n",
      "Time taken to load model = 11.25682806968689 seconds\r\n",
      "Time Taken to run 100 Inference is = 1.122713565826416 seconds\r\n",
      "None.txt\r\n",
      "stderr.log\r\n"
     ]
    }
   ],
   "source": [
    "!cat stdout.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_4rf323l"
   },
   "source": [
    "## Step 6: View the Outputs\n",
    "\n",
    "Can you plot the load time, inference time and the frames per second in the cell below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_bkny5ta"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#File Paths to stats files\n",
    "paths=['gpu_stats.txt', 'cpu_stats.txt']\n",
    "\n",
    "# TODO: Plot the different stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_m9kxw9k"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_m9kxw9k-id_4h5tl2h\"><i></i><button>Hide Solution</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "graffitiCellId": "id_4h5tl2h"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-74f365950283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fpga_cpu_stats.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cpu_gpu_stats.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fpga_gpu_cpu_stats.txt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'FPGA/CPU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CPU/GPU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FPGA/GPU/CPU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-74f365950283>\u001b[0m in \u001b[0;36mread_files\u001b[0;34m(paths, labels)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mfps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Model Load Time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Inference Time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Frames per Second'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Frames'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-74f365950283>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(labels, data, title, label)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2079\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[1;32m   2080\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'vertical'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(labels, data, title, label):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.set_ylabel(label)\n",
    "    ax.set_title(title)\n",
    "    ax.bar(labels, data)\n",
    "    \n",
    "def read_files(paths, labels):\n",
    "    load_time=[]\n",
    "    inference_time=[]\n",
    "    fps=[]\n",
    "    \n",
    "    for path in paths:\n",
    "        if os.path.isfile(path):\n",
    "            f=open(path, 'r')\n",
    "            load_time.append(float(f.readline()))\n",
    "            inference_time.append(float(f.readline()))\n",
    "            fps.append(float(f.readline()))\n",
    "\n",
    "    plot(labels, load_time, 'Model Load Time', 'seconds')\n",
    "    plot(labels, inference_time, 'Inference Time', 'seconds')\n",
    "    plot(labels, fps, 'Frames per Second', 'Frames')\n",
    "\n",
    "paths=['fpga_cpu_stats.txt', 'cpu_gpu_stats.txt', 'fpga_gpu_cpu_stats.txt']\n",
    "read_files(paths, ['FPGA/CPU', 'CPU/GPU', 'FPGA/GPU/CPU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_0c20r8n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "graffiti": {
   "firstAuthorId": "dca260a8-2142-11ea-b0f7-6f7abbbf2f85",
   "id": "id_610hfgn",
   "language": "EN"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
